{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbae557-5b3f-43ab-ae82-b2c7e5a60a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3587d5e-9cb8-458f-b945-43887a76f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121cd3ac-525e-40b8-b116-1f65ff26c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow opencv-python streamlit numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e1bbe-4ebd-4e1d-8efa-f70581da7603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load the pretrained model\n",
    "model = load_model(\"../model/face_mask_detector.model\")\n",
    "\n",
    "\n",
    "# Step 2: Load and display a sample test image\n",
    "img = cv2.imread(\"test_face.jpeg\")  # Add any photo of a face and name it test_face.jpg\n",
    "print(\"Image loaded:\", img is not None)\n",
    "\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_rgb)\n",
    "plt.axis('off')\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Preprocess the image for the model\n",
    "img_resized = cv2.resize(img, (224, 224))\n",
    "img_normalized = img_resized / 255.0\n",
    "img_input = np.expand_dims(img_normalized, axis=0)  # Add batch dimension\n",
    "\n",
    "# Step 4: Get prediction\n",
    "prediction = model.predict(img_input)[0][0]\n",
    "\n",
    "# Step 5: Interpret the prediction\n",
    "if prediction > 0.5:\n",
    "    print(\"ðŸŸ¢ MASK detected âœ… (Confidence:\", prediction, \")\")\n",
    "else:\n",
    "    print(\"ðŸ”´ NO MASK detected âŒ (Confidence:\", prediction, \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578f383-2254-4b06-ac2c-023eab65efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Add label to the image\n",
    "label = \"MASK\" if prediction > 0.5 else \"NO MASK\"\n",
    "color = (0, 255, 0) if prediction > 0.5 else (255, 0, 0)\n",
    "\n",
    "# Add label text to image (on a copy to preserve original)\n",
    "img_copy = img.copy()\n",
    "cv2.putText(img_copy, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            1.0, color, 2, cv2.LINE_AA)\n",
    "\n",
    "# Convert to RGB for matplotlib\n",
    "img_rgb_labeled = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display with matplotlib\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img_rgb_labeled)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Prediction: {label}\")\n",
    "plt.show()\n",
    "\n",
    "# Save the result\n",
    "cv2.imwrite(\"predicted_test_face.png\", img_copy)\n",
    "print(\"âœ… Image saved as 'predicted_test_face.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2a4b2-4cd3-44da-ae41-3c5e6a4b16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenCV's pre-trained Haar cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Convert image to grayscale (required for Haar cascades)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d41e8-899c-4e09-aab7-74dc6bc2fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect faces â†’ returns a list of rectangles (x, y, w, h)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3, minSize=(30, 30))\n",
    "\n",
    "print(\"Faces found:\", len(faces))\n",
    "\n",
    "# Draw rectangles around faces and predict for each\n",
    "for (x, y, w, h) in faces:\n",
    "    # Crop the face region\n",
    "    face = img[y:y+h, x:x+w]\n",
    "\n",
    "    # Resize, normalize, and expand dimensions\n",
    "    face_resized = cv2.resize(face, (224, 224)) / 255.0\n",
    "    face_input = np.expand_dims(face_resized, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    pred = model.predict(face_input)[0][0]\n",
    "    label = \"MASK âœ…\" if pred > 0.5 else \"NO MASK âŒ\"\n",
    "    confidence = round(pred if pred > 0.5 else 1 - pred, 3)\n",
    "\n",
    "    # Draw bounding box + label\n",
    "    color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(img, f\"{label} ({confidence})\", (x, y - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "# Show the image with predictions\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Face Detection + Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b25061-9eea-4b36-8efd-728462a2f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a new image\n",
    "img2 = cv2.imread(\"test_face_2.jpg\")\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect face\n",
    "faces2 = face_cascade.detectMultiScale(gray2, scaleFactor=1.05, minNeighbors=3, minSize=(30, 30))\n",
    "print(\"Faces found:\", len(faces2))\n",
    "\n",
    "# Predict on each face\n",
    "for (x, y, w, h) in faces2:\n",
    "    face = img2[y:y+h, x:x+w]\n",
    "    face_resized = cv2.resize(face, (224, 224)) / 255.0\n",
    "    face_input = np.expand_dims(face_resized, axis=0)\n",
    "    pred = model.predict(face_input)[0][0]\n",
    "    label = \"MASK âœ…\" if pred > 0.5 else \"NO MASK âŒ\"\n",
    "    confidence = round(pred if pred > 0.5 else 1 - pred, 3)\n",
    "    color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)\n",
    "    \n",
    "    cv2.rectangle(img2, (x, y), (x+w, y+h), color, 2)\n",
    "    cv2.putText(img2, f\"{label} ({confidence})\", (x, y - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "# Show result\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title(\"Second Face Test\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f9586-c2a8-4a8d-8a4f-a329adb67f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48166e-eeee-4cf6-a359-6c478760d6db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cad49-9278-4b8a-9252-750a308012ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
